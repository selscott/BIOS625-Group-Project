---
title: "Pre-processing"
author: "Selena Scott"
date: "12/12/21"
output: pdf_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, tidy.opts = list(width.cutoff=60))
library (dplyr)
library (stringr)
library (tm)
library (topicmodels)
library (kableExtra)
library (textmineR)
library (ggplot2)
library (reshape2)
library (tidytext)
library(readr)
library(viridis)
```

# Topic Modeling
## 1) Prepare the Data
```{r, eval = F}
# the following chunk of code is not run b/c it takes a long time, 
# the results are saved and loaded into the next chunk
data = read_csv("../Answers.csv")

# first column has to be named "doc_id", second column has to be named "text"
data$doc_id = data$Id
data$text = data$Body
data = data[, c(8, 9, 2:6)]

# make a corpus (data structure for text data, need it to be in this form to make a document-term matrix)
corpus = tm::Corpus(DataframeSource(as.data.frame(data)))

english_stopwords = readLines("https://slcladal.github.io/resources/stopwords_en.txt", encoding = "UTF-8")

processedCorpus = tm_map(corpus, content_transformer(tolower))  # make text lowercase
processedCorpus = tm_map(processedCorpus, removePunctuation, preserve_intra_word_dashes = TRUE)  # remove punctuation
processedCorpus = tm_map(processedCorpus, removeWords, english_stopwords)  # remove common stopwords
processedCorpus = tm_map(processedCorpus, removeNumbers)  # remove numbers
processedCorpus = tm_map(processedCorpus, stemDocument, language = "en")  # only keep bases of words
processedCorpus = tm_map(processedCorpus, stripWhitespace)  # remove extra whitespace

# make a document-term matrix (data structure for text data, need it to be in this form for model)
ndocs = length(corpus)
minimumFrequency = ndocs * 0.02  # include words appearing in at least 2% of documents
maximumFrequency = ndocs * 0.8  # remove words appearing in more than 80% of documents

DTM = tm::DocumentTermMatrix(processedCorpus, control = list(bounds = list(global = c(minimumFrequency, maximumFrequency))))
save(DTM, data, processedCorpus, file = "preprocessing/DTM_preprocessing.dta")
```

```{r}
load("preprocessing/DTM_preprocessing.dta")
dim(DTM)  # 250788 documents, 220 terms
```

Run an initial model to see if extra cleaning is needed.
```{r}
sel_idx = slam::row_sums(DTM) > 0  # remove documents that don't have any words
DTM = DTM[sel_idx, ]

K = 8  # set an arbitrary number of topics (attempted K = 20 > 15 > 10 > 9 > 8)
set.seed(9161)  # set random number generator seed

# the following line takes a while to run, the results are saved
# compute the LDA model, inference via 500 iterations of Gibbs sampling
#topicModel = LDA(DTM, K, method = "Gibbs", control = list(iter = 500, verbose = 25))
#save(topicModel, file = "preprocessing/topicModel_preprocessing.dta")

load("preprocessing/topicModel_preprocessing.dta")

top15termsPerTopic = terms(topicModel, 15)  # top 15 words per topic
topicNames = apply(top15termsPerTopic, 2, paste, collapse = " ")
topicNames %>% kable(col.names = c("terms"))
```

## 2) Rename Topics
```{r}
topicNames = data.frame(terms = topicNames)

topicNames$topic_name = c("function definitions and calls",
                          "dates and times",
                          "installing and loading packages",
                          "vectors",
                          "strings",
                          "lists and variables",
                          "plots and figures",
                          "data frames and matrices")
```

## 3) Add Topics to Data
```{r, eval = F}
# topic proportions
tmResult = topicmodels::posterior(topicModel)
theta = as.data.frame(tmResult$topics)
theta$doc_id = as.numeric(dimnames(theta)[[1]])

# add topic proportions to data
data = left_join(data, theta, by = "doc_id")

# add main topic variable to data
data$main_topic = max.col(as.matrix((data[, 8:15])), ties.method = "first")

# add clean text
temp = processedCorpus$content
temp = as.data.frame(cbind(names(temp), temp))
names(temp) = c("doc_id", "clean_text")
temp$doc_id = as.numeric(data$doc_id)
data = left_join(data, temp, by = "doc_id")

# add variables for number of words in text
data$n_words_original = lengths(gregexpr("[A-z]\\W+", data$text)) + 1L
data$n_words_clean = lengths(gregexpr("[A-z]\\W+", data$clean_text)) + 1L

# re-order columns
data = data[, c(1:7, 16, 8:15, 18:19, 17)]

# select columns
topics = data[, c(1, 8:18)]

# save data frames
save(topics, file = "data/topics.RData")
#save(data, file = "data/answers_topics.RData")
```

## 4) Plot
```{r}
load("data/topics.RData")

# subset of observations
topics_complete = topics[complete.cases(topics),]
topics_subset = topics_complete[1:50,]

# rename topic proportion columns
colnames(topics_subset)[3:10] = topicNames$topic_name

# long format
topics_long = melt(topics_subset, id.vars = "doc_id",
                   measure.vars = topicNames$topic_name,
                   variable.name = "topic_character",
                   value.name = "topic_proportion")

topics_long$topic_numeric = as.numeric(topics_long$topic_character)
topics_long = topics_long[order(topics_long$doc_id, topics_long$topic_numeric),]

# prepare data frame for plot
topics_long = topics_long[, c(1, 4, 2, 3)]
topics_long$doc_id = as.factor(topics_long$doc_id)

# plot
## color scheme (1)
ggplot(topics_long, aes(x = doc_id, y = topic_proportion, fill = topic_character)) + 
  geom_bar(stat = "identity") +
  labs(x = "Answer", y = "Proportion") +
  scale_fill_discrete(name = "Topic") +
  scale_x_discrete(labels = NULL) +
  theme(plot.title = element_text(size = 12),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "black", fill = NA, size = 0.5),
        panel.grid = element_line(color = rgb(235, 235, 235, 100, maxColorValue = 255)))

ggsave(file = "plots/topics.png", plot = last_plot(), width = 10, height = 6, units = "in")

## color scheme (2)
ggplot(topics_long, aes(x = doc_id, y = topic_proportion, fill = topic_character)) + 
  geom_bar(stat = "identity") +
  labs(x = "Answer", y = "Proportion") +
  scale_fill_viridis_d(option = "mako", direction = -1, name = "Topic") +
  scale_x_discrete(labels = NULL) +
  theme(plot.title = element_text(size = 12),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "black", fill = NA, size = 0.5),
        panel.grid = element_line(color = rgb(235, 235, 235, 100, maxColorValue = 255)))

ggsave(file = "plots/topics.png", plot = last_plot(), width = 10, height = 6, units = "in")
```

## 5) Table
```{r}
# topics and terms data frame
topics_df = topicNames[, c(2, 1)]
rownames(topics_df) = 1:8
colnames(topics_df) = c("Topic", "Terms")

# clean up terms
#terms(topicModel, 20)
topics_df$Terms[1] = "function code call return object argument the error result method pass defin loop oper assign"
topics_df$Terms[3] = "packag work file problem test run version read instal user check comment sourc load find"
topics_df$Terms[4] = "true fals vector functionx element length null sep you this here solut result fun collaps"
topics_df$Terms[5] = "you class output if charact string match option replac remov numer convert input this or"
topics_df$Terms[7] = "plot imag line descript add label point size text here color set you fill chang"

#save(topics_df, file = "data/terms_table.RData")

# table
kbl(topics_df,
    caption = "Top 15 Terms Per Topic",
    booktabs = T, longtable = T, linesep = "") %>%
  collapse_rows(columns = 1, latex_hline = "major", valign = "top") %>%
  kable_styling(full_width = T)
```
